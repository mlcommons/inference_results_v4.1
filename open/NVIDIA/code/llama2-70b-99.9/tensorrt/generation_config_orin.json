{
    "generation_config": {
      "min_output_len": 1,
      "max_output_len": 768,
      "runtime_beam_width": 1,
      "temperature": 1.0,
      "top_k": 1,
      "top_p": 0.0,
      "use_stop_tokens": false,
      "streaming": true,
      "eos_token_id": 2,
      "name": "llama"
    }
}